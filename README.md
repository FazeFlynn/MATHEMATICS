# The Vector Space Rules
## Group 1ï¸âƒ£: Rules that make addition behave sensibly (5 rules)

These ensure **vector addition behaves like normal addition**.

### 1. Closure under addition

If **${v}$** and **${w}$** are in the space, then **${v + w}$** is also in the space

ğŸ“Œ Without this: adding vectors could throw you outside the universe.

---

### 2. Commutativity

$$
{v + w = w + v}
$$

ğŸ“Œ Direction shouldnâ€™t depend on order.

---

### 3. Associativity

$$
{(v + w) + u = v + (w + u)}
$$

ğŸ“Œ Grouping shouldnâ€™t change meaning.

---

### 4. Additive identity (zero vector)

$$
{v + 0 = v}
$$

ğŸ“Œ There must be a â€œdo nothingâ€ vector.

---

### 5. Additive inverse

$$
{v + (âˆ’v) = 0}
$$

ğŸ“Œ Every move must be undoable.

---

## Group 2ï¸âƒ£: Rules that make scaling behave sensibly (4 rules)

These ensure **scalars interact cleanly with vectors**.

### 6. Closure under scalar multiplication

${Î±v}$ is in the space for any scalar ${Î±}$

ğŸ“Œ Otherwise scaling could destroy structure.

---

### 7. Distributivity over vector addition

$$
{Î±(v + w) = Î±v + Î±w}
$$

ğŸ“Œ Scaling a sum should match summing scaled parts.

---

### 8. Distributivity over scalar addition

$$
{(Î± + Î²)v = Î±v + Î²v}
$$

ğŸ“Œ Multiple scalings should combine logically.

---

### 9. Associativity of scalar multiplication

$$
{Î±(Î²v) = (Î±Î²)v}
$$

ğŸ“Œ Scaling order must not matter.

---

## Group 3ï¸âƒ£: Rule that links vectors to numbers (1 rule)

### ğŸ”Ÿ Scalar identity

$$
{1 Â· v = v}
$$

ğŸ“Œ Multiplying by â€œoneâ€ should change nothing.


---
---

<br>



# Linear Transformation Rules


## 1ï¸âƒ£ Rule 1: Additivity (preserve addition)

$$
\boxed{T(v + w) = T(v) + T(w)}
$$

Meaning:

Transforming ${a}$ sum = summing the transforms

---

##  2ï¸âƒ£ Rule 2: Homogeneity (preserve scaling)

$$
\boxed{T(\alpha v) = \alpha T(v)}
$$

Meaning:

Scaling first or transforming first gives the same result


---
---

<br>

# EigenValues & Eigenvectors 

${\Rightarrow}$ An **eigenvector** is a **non-zero vector whose direction does not change** under a linear transformation â€” only its length may change.
If direction changes â†’ **not** an eigenvector.

---

## 2ï¸âƒ£ The defining equation (this is the ONLY starting point)

For a matrix ${A}$:

$$
{\boxed{A\mathbf{v} = \lambda \mathbf{v}}}
$$

Where:

* ${\mathbf{v} \neq 0}$ â†’ eigenvector
* ${\lambda}$ â†’ eigenvalue (scaling factor)

This equation **defines** eigenvalues & eigenvectors.
Everything else comes from this.

---

## 3ï¸âƒ£ Why this equation makes sense (intuition)

* ${A\mathbf{v}}$ â†’ apply transformation
* ${\lambda\mathbf{v}}$ â†’ same direction, scaled

So:

* Same direction âœ”
* Possibly stretched or flipped âœ”

---

## 4ï¸âƒ£ Turning the definition into a solvable formula

Start from:

$$
{A\mathbf{v} = \lambda \mathbf{v}}
$$

Move everything to one side:

$$
{A\mathbf{v} - \lambda \mathbf{v} = 0}
$$

Factor out (\mathbf{v}):

$$
{(A - \lambda I)\mathbf{v} = 0}
$$

This is the **core equation**.

---

## 5ï¸âƒ£ The NON-TRIVIAL condition (very important)

The equation:
$$
{(A - \lambda I)\mathbf{v} = 0}
$$

has:

* trivial solution ${\mathbf{v}=0}$ â†’ useless âŒ
* non-zero solution â†’ eigenvector âœ”

A non-zero solution exists **only if**:

$$
{\boxed{\det(A - \lambda I) = 0}}
$$

ğŸ‘‰ **THIS is the eigenvalue rule**

---

## 6ï¸âƒ£ Step-by-step RULES to find eigenvalues

### RULE 1: Form ${A - \lambda I}$

Subtract ${\lambda}$ from the diagonal of ${A}$.

---

### RULE 2: Take determinant

$$
{\det(A - \lambda I)}
$$

---

### RULE 3: Set determinant = 0

$$
{\det(A - \lambda I) = 0}
$$

This gives the **characteristic equation**.

---

### RULE 4: Solve for ${\lambda}$

Solutions are the **eigenvalues**.

---

## 7ï¸âƒ£ Full worked example (â„Â², no shortcuts)

Let:

$$
{A = \begin{bmatrix}
2 & 1 \\
1 & 2
\end{bmatrix}}
$$

---

### Step 1: Compute ${A - \lambda I}$

$$
{\begin{bmatrix}
2-\lambda & 1 \\
1 & 2-\lambda
\end{bmatrix}}
$$

---

### Step 2: Determinant

$$
{(2-\lambda)^2 - 1}
$$

---

### Step 3: Set equal to zero

$$
{(2-\lambda)^2 - 1 = 0}
$$

---

### Step 4: Solve

$$
{(2-\lambda)^2 = 1}
$$

$$
{2-\lambda = \pm 1}
$$

$$
{\lambda = 1,; 3}
$$

âœ… **Eigenvalues found**

---

## 8ï¸âƒ£ RULES to find eigenvectors (for each eigenvalue)

For **each** eigenvalue (\lambda):

---

### RULE 5: Plug (\lambda) back into

$$
{(A - \lambda I)\mathbf{v} = 0}
$$

---

### RULE 6: Solve the linear system

This gives eigenvectors.

---

## 9ï¸âƒ£ Eigenvector example (complete)

### For ${\lambda = 3}$

$$
{
A - 3I =
\begin{bmatrix}
-1 & 1 \\
1 & -1
\end{bmatrix}
}
$$

Solve:

$$
{
-x + y = 0 \Rightarrow y = x
}
$$

Eigenvectors:

$$
{
\mathbf{v} =
\begin{bmatrix}
1 \\
1
\end{bmatrix},
\begin{bmatrix}
2 \\
2
\end{bmatrix},
\text{etc.}
}
$$

(Any non-zero multiple)

---

### For ${\lambda = 1}$

$$
{
A - I =
\begin{bmatrix}
1 & 1 \\
1 & 1
\end{bmatrix}
}
$$

Solve:

$$
{
x + y = 0
\Rightarrow y = -x
}
$$

Eigenvectors:
$$
{
\begin{bmatrix}
1 \\
-1
\end{bmatrix}
}
$$


---

## ğŸ”Ÿ Important rules people forget (memorize)

### Rule A: Eigenvectors are NEVER unique

If ${\mathbf{v}}$ is one â†’ ${c\mathbf{v}}$ also is.

---

### Rule B: Zero vector is NEVER an eigenvector

By definition.

---

### Rule C: Number of eigenvalues â‰¤ matrix size

* 2Ã—2 â†’ max 2
* 3Ã—3 â†’ max 3

(Counting multiplicity)

---

### Rule D: No eigenvectors? Possible.

Example:

* Rotation by 90Â° in â„Â² â†’ **no real eigenvectors**

---

## 1ï¸âƒ£1ï¸âƒ£ Quick failure examples (to sharpen intuition)

### âŒ Nonlinear transformation

Eigenvalues are defined **only for linear transformations**.

---

### âŒ Translation

$$
{T(x)=Ax+b}
$$

No eigenvectors unless (${b}$=0).

---

## 1ï¸âƒ£2ï¸âƒ£ Why eigenvalues matter (intuition)


* PCA â†’ eigenvectors = principal directions
* Stability â†’ eigenvalues control explosion/decay
* Differential equations â†’ long-term behavior
* NN â†’ gradient flow & conditioning

---

## FINAL LOCK-IN (this ends confusion)

### Eigenvalue rule

$$
{\boxed{\det(A - \lambda I) = 0}}
$$

### Eigenvector rule

$$
{\boxed{(A - \lambda I)\mathbf{v} = 0,;\mathbf{v}\neq0}}
$$

---

## One-sentence intuition ğŸ”’

**Eigenvectors are directions a transformation cannot bend â€” it can only stretch or flip them.**

---
---

<br>






$$
{End\,of\,file}
$$

# The Vector Space Rules
## Group 1Ô∏è‚É£: Rules that make addition behave sensibly (5 rules)

These ensure **vector addition behaves like normal addition**.

### 1. Closure under addition

If **${v}$** and **${w}$** are in the space, then **${v + w}$** is also in the space

üìå Without this: adding vectors could throw you outside the universe.

---

### 2. Commutativity

$$
{v + w = w + v}
$$

üìå Direction shouldn‚Äôt depend on order.

---

### 3. Associativity

$$
{(v + w) + u = v + (w + u)}
$$

üìå Grouping shouldn‚Äôt change meaning.

---

### 4. Additive identity (zero vector)

$$
{v + 0 = v}
$$

üìå There must be a ‚Äúdo nothing‚Äù vector.

---

### 5. Additive inverse

$$
{v + (‚àív) = 0}
$$

üìå Every move must be undoable.

---

## Group 2Ô∏è‚É£: Rules that make scaling behave sensibly (4 rules)

These ensure **scalars interact cleanly with vectors**.

### 6. Closure under scalar multiplication

${Œ±v}$ is in the space for any scalar ${Œ±}$

üìå Otherwise scaling could destroy structure.

---

### 7. Distributivity over vector addition

$$
{Œ±(v + w) = Œ±v + Œ±w}
$$

üìå Scaling a sum should match summing scaled parts.

---

### 8. Distributivity over scalar addition

$$
{(Œ± + Œ≤)v = Œ±v + Œ≤v}
$$

üìå Multiple scalings should combine logically.

---

### 9. Associativity of scalar multiplication

$$
{Œ±(Œ≤v) = (Œ±Œ≤)v}
$$

üìå Scaling order must not matter.

---

## Group 3Ô∏è‚É£: Rule that links vectors to numbers (1 rule)

### üîü Scalar identity

$$
{1 ¬∑ v = v}
$$

üìå Multiplying by ‚Äúone‚Äù should change nothing.



---

$$
{\color{yellow}\text{***************************************************************************************************}}
$$


# Linear Transformation Rules


## 1Ô∏è‚É£ Rule 1: Additivity (preserve addition)

$$
\boxed{T(v + w) = T(v) + T(w)}
$$

Meaning:

Transforming ${a}$ sum = summing the transforms

---

##  2Ô∏è‚É£ Rule 2: Homogeneity (preserve scaling)

$$
\boxed{T(\alpha v) = \alpha T(v)}
$$

Meaning:

Scaling first or transforming first gives the same result

---

$$
{\color{yellow}\text{***************************************************************************************************}}
$$

# EigenValues & Eigenvectors 

> ${\Rightarrow}$ An **eigenvector** is a **non-zero vector whose direction does not change** under a linear transformation ‚Äî only its length may change.
If direction changes ‚Üí **not** an eigenvector.

---

## 2Ô∏è‚É£ The defining equation (this is the ONLY starting point)

For a matrix ${A}$:

$$
{\boxed{A\mathbf{v} = \lambda \mathbf{v}}}
$$

Where:

* ${\mathbf{v} \neq 0}$ ‚Üí eigenvector
* ${\lambda}$ ‚Üí eigenvalue (scaling factor)

This equation **defines** eigenvalues & eigenvectors.
Everything else comes from this.

---

## 3Ô∏è‚É£ Why this equation makes sense (intuition)

* ${A\mathbf{v}}$ ‚Üí apply transformation
* ${\lambda\mathbf{v}}$ ‚Üí same direction, scaled

So:

* Same direction ‚úî
* Possibly stretched or flipped ‚úî

---

## 4Ô∏è‚É£ Turning the definition into a solvable formula

Start from:

$$
{A\mathbf{v} = \lambda \mathbf{v}}
$$

Move everything to one side:

$$
{A\mathbf{v} - \lambda \mathbf{v} = 0}
$$

Factor out (\mathbf{v}):

$$
{(A - \lambda I)\mathbf{v} = 0}
$$

This is the **core equation**.

---

## 5Ô∏è‚É£ The NON-TRIVIAL condition (very important)

The equation:

$$
{(A - \lambda I)\mathbf{v} = 0}
$$

has:

* trivial solution ${\mathbf{v}=0}$ ‚Üí useless ‚ùå
* non-zero solution ‚Üí eigenvector ‚úî

A non-zero solution exists **only if**:

$$
{\boxed{\det(A - \lambda I) = 0}}
$$

üëâ **THIS is the eigenvalue rule**

---

## 6Ô∏è‚É£ Step-by-step RULES to find eigenvalues

### RULE 1: Form ${A - \lambda I}$

Subtract ${\lambda}$ from the diagonal of ${A}$.

---

### RULE 2: Take determinant

$$
{\det(A - \lambda I)}
$$

---

### RULE 3: Set determinant = 0

$$
{\det(A - \lambda I) = 0}
$$

This gives the **characteristic equation**.

---

### RULE 4: Solve for ${\lambda}$

Solutions are the **eigenvalues**.

---

## 7Ô∏è‚É£ Full worked example (‚Ñù¬≤, no shortcuts)

Let:

$$
{A = \begin{bmatrix}
2 & 1 \\
1 & 2
\end{bmatrix}}
$$

---

### Step 1: Compute ${A - \lambda I}$

$$
{\begin{bmatrix}
2-\lambda & 1 \\
1 & 2-\lambda
\end{bmatrix}}
$$

---

### Step 2: Determinant

$$
{(2-\lambda)^2 - 1}
$$

---

### Step 3: Set equal to zero

$$
{(2-\lambda)^2 - 1 = 0}
$$

---

### Step 4: Solve

$$
{(2-\lambda)^2 = 1}
$$

$$
{2-\lambda = \pm 1}
$$

$$
{\lambda = 1,; 3}
$$

‚úÖ **Eigenvalues found**

---

## 8Ô∏è‚É£ RULES to find eigenvectors (for each eigenvalue)

For **each** eigenvalue (\lambda):

---

### RULE 5: Plug (\lambda) back into

$$
{(A - \lambda I)\mathbf{v} = 0}
$$

---

### RULE 6: Solve the linear system

This gives eigenvectors.

---

## 9Ô∏è‚É£ Eigenvector example (complete)

### For ${\lambda = 3}$

$$
{
A - 3I =
\begin{bmatrix}
-1 & 1 \\
1 & -1
\end{bmatrix}
}
$$

Solve:

$$
{
-x + y = 0 \Rightarrow y = x
}
$$

Eigenvectors:

$$
{
\mathbf{v} =
\begin{bmatrix}
1 \\
1
\end{bmatrix},
\begin{bmatrix}
2 \\
2
\end{bmatrix},
\text{etc.}
}
$$

(Any non-zero multiple)

---

### For ${\lambda = 1}$

$$
{
A - I =
\begin{bmatrix}
1 & 1 \\
1 & 1
\end{bmatrix}
}
$$

Solve:

$$
{
x + y = 0
\Rightarrow y = -x
}
$$

Eigenvectors:
$$
{
\begin{bmatrix}
1 \\
-1
\end{bmatrix}
}
$$


---

## üîü Important rules people forget (memorize)

### Rule A: Eigenvectors are NEVER unique

If ${\mathbf{v}}$ is one ‚Üí ${c\mathbf{v}}$ also is.

---

### Rule B: Zero vector is NEVER an eigenvector

By definition.

---

### Rule C: Number of eigenvalues ‚â§ matrix size

* 2√ó2 ‚Üí max 2
* 3√ó3 ‚Üí max 3

(Counting multiplicity)

---

### Rule D: No eigenvectors? Possible.

Example:

* Rotation by 90¬∞ in ‚Ñù¬≤ ‚Üí **no real eigenvectors**

---

## 1Ô∏è‚É£1Ô∏è‚É£ Quick failure examples (to sharpen intuition)

### ‚ùå Nonlinear transformation

Eigenvalues are defined **only for linear transformations**.

---

### ‚ùå Translation

$$
{T(x)=Ax+b}
$$

No eigenvectors unless (${b}$=0).

---

## 1Ô∏è‚É£2Ô∏è‚É£ Why eigenvalues matter (intuition)


* PCA ‚Üí eigenvectors = principal directions
* Stability ‚Üí eigenvalues control explosion/decay
* Differential equations ‚Üí long-term behavior
* NN ‚Üí gradient flow & conditioning

---

## FINAL LOCK-IN (this ends confusion)

### Eigenvalue rule

$$
{\boxed{\det(A - \lambda I) = 0}}
$$

### Eigenvector rule

$$
{\boxed{(A - \lambda I)\mathbf{v} = 0,;\mathbf{v}\neq0}}
$$

---

## One-sentence intuition üîí

**Eigenvectors are directions a transformation cannot bend ‚Äî it can only stretch or flip them.**

---
---

<br>






$$
{End\,of\,file}
$$
